{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francesco-source/DeepLearning/blob/main/mnistDense.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wSwJnsjx5P"
      },
      "source": [
        "# Mnist classification with NNs\n",
        "A first example of a simple Neural Network, applied to a well known dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wMZ2Ge6jw1E"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDiNppLVkvqd"
      },
      "source": [
        "Let us load the mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL8GyC0Nk14o"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijhDuLwwlQrI",
        "outputId": "4b5b338e-31b4-401d-dc5b-86d1a3da2529"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(\"pixel range is [{},{}]\".format(np.min(x_train),np.max(x_train)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "pixel range is [0,255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01L64YcnWO5"
      },
      "source": [
        "We normalize the input in the range [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8uA2Kp7mG9s"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = np.reshape(x_train,(60000,28*28))\n",
        "x_test = np.reshape(x_test,(10000,28*28))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the network will be a proability distribution over the different categories. Similarly, we generate a ground truth distribution, and the training objective will consist in minimizing their distance (categorical crossentropy). The ground truth distribution is the so called \"categorical\" distribution: if x has label l, the corresponding categorical distribution has probaility 1 for the category l, and 0 for all the others."
      ],
      "metadata": {
        "id": "Yjrzmhgh3TZv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzWUm0UnODb",
        "outputId": "64ca139b-0022-407e-d1c9-ecf987fa5e3b"
      },
      "source": [
        "print(y_train[0])\n",
        "y_train_cat = utils.to_categorical(y_train)\n",
        "print(y_train_cat[0])\n",
        "y_test_cat = utils.to_categorical(y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfeZF3bUrFZf"
      },
      "source": [
        "Our first Netwok just implements logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBJtMj2pqJiR"
      },
      "source": [
        "xin = Input(shape=(784))\n",
        "res = Dense(10,activation='softmax')(xin)\n",
        "\n",
        "mynet = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXD5JT2ZrTJc",
        "outputId": "508197e6-0b1d-4a8c-cefa-c1a99bc2fca7"
      },
      "source": [
        "mynet.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjcOz8yrk5X"
      },
      "source": [
        "Now we need to compile the network.\n",
        "In order to do it, we need to pass two mandatory arguments:\n",
        "\n",
        "\n",
        "*   the **optimizer**, in charge of governing the details of the backpropagation algorithm\n",
        "*   the **loss function**\n",
        "\n",
        "Several predefined optimizers exist, and you should just choose your favourite one. A common choice is Adam, implementing an adaptive lerning rate, with momentum\n",
        "\n",
        "Optionally, we can specify additional metrics, mostly meant for monitoring the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XK20mAFrrkQ"
      },
      "source": [
        "mynet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E58bT-Imvsw2"
      },
      "source": [
        "Finally, we fit the model over the trianing set. \n",
        "\n",
        "Fitting, just requires two arguments: training data e ground truth, that is x and y. Additionally we can specify epochs, batch_size, and many additional arguments.\n",
        "\n",
        "In particular, passing validation data allow the training procedure to measure loss and metrics on the validation set at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2woDXbbr6ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f7c3ed-a5d0-41a0-fb59-81ddf4ea1433"
      },
      "source": [
        "mynet.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 3ms/step - loss: 0.4653 - accuracy: 0.8789 - val_loss: 0.3104 - val_accuracy: 0.9159\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3033 - accuracy: 0.9164 - val_loss: 0.2817 - val_accuracy: 0.9225\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2831 - accuracy: 0.9211 - val_loss: 0.2740 - val_accuracy: 0.9245\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2729 - accuracy: 0.9245 - val_loss: 0.2696 - val_accuracy: 0.9256\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2663 - accuracy: 0.9259 - val_loss: 0.2682 - val_accuracy: 0.9262\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2616 - accuracy: 0.9271 - val_loss: 0.2652 - val_accuracy: 0.9260\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2579 - accuracy: 0.9279 - val_loss: 0.2713 - val_accuracy: 0.9226\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2557 - accuracy: 0.9293 - val_loss: 0.2642 - val_accuracy: 0.9267\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2531 - accuracy: 0.9301 - val_loss: 0.2684 - val_accuracy: 0.9264\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2511 - accuracy: 0.9309 - val_loss: 0.2689 - val_accuracy: 0.9251\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85d181c940>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0mBuorMulG5"
      },
      "source": [
        "xin = Input(shape=(784))\n",
        "x = Dense(128,activation='relu')(xin)\n",
        "res = Dense(10,activation='softmax')(x)\n",
        "\n",
        "mynet2 = Model(inputs=xin,outputs=res)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpMyvw7buzhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7662eca-5939-4080-fd06-5587ede0e18f"
      },
      "source": [
        "mynet2.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYg0odW2u6cn"
      },
      "source": [
        "mynet2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDnzgIZVvGOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6bab41-9660-4fb6-a407-0084a46db5a3"
      },
      "source": [
        "mynet2.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2587 - accuracy: 0.9270 - val_loss: 0.1352 - val_accuracy: 0.9598\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1149 - accuracy: 0.9665 - val_loss: 0.1025 - val_accuracy: 0.9686\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0784 - accuracy: 0.9763 - val_loss: 0.0889 - val_accuracy: 0.9734\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 0.0733 - val_accuracy: 0.9782\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.0737 - val_accuracy: 0.9769\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 0.0717 - val_accuracy: 0.9791\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0755 - val_accuracy: 0.9779\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0715 - val_accuracy: 0.9793\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0758 - val_accuracy: 0.9789\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0789 - val_accuracy: 0.9785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85ce518970>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcUKxCzKwzG9"
      },
      "source": [
        "An amazing improvement. WOW!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJr0EnAkw6nf"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1.   Add additional Dense layers and check the performance of the network\n",
        "2.   Replace 'relu' with different activation functions\n",
        "3. Adapt the network to work with the so called sparse_categorical_crossentropy\n",
        "4. the fit function return a history of training, with temporal sequences for all different metrics. Make a plot.\n",
        "\n",
        "\\\\"
      ]
    }
  ]
}